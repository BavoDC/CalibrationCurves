---
title: "Two stage meta-analysis calibration (2MA-C)"
author:
  - name: Lasai Barre√±ada
    orcid: 0000-0001-8020-0210
    email: lasai.barrenadataleb@kueleuven.be
    affiliations:
      - name: Department of Development and Regeneration, KU Leuven, Belgium
format:
  html:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: hide
    code-fold: true
    theme: readable
    fig-width: 8
    fig-height: 6

---
  
```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(metafor)
library(meta)
library(plotrix)
library(ggnewscale)
library(rms)
```

## Method Overview

**Stage 1**

Fit a model per center and estimate observed proportion for a grid of values (e.g., 100 values from 0.001 to 0.999):

$$
\text{logit}(y_{ji}) = \alpha_j + \beta_j \cdot \eta_{ji}
$$
---

**Stage 2**

Pool observed proportion per grid value $g$ using a random effects model:

$$
\hat{y}_{gj} = y_g + u_{gj} + \epsilon_{gj}, \quad \epsilon_j \sim N(0, \sigma_{gj}^2), \quad u_j \sim N(0, \tau_g^2)
$$

Where:
$\hat{y}_{gj}$ is the estimated observed proportion from model $j$ for value $g$ in the grid.
$u_j$ is the random effect for center $k$.
$\(\epsilon_j\)$ is the sampling error or within-study variance.

Here:
$\tau_g^2$ is the between-study variability or heterogeneity, estimated using REML.
$s_j^2$ is the within-study variability.

Confidence intervals can be calculated using:

 **Default Method**: $\hat{y}_g \pm z_{1 - \alpha/2} \cdot SE(\hat{y}_g)$


 **HKSJ Method**: $\hat{y}_g \pm t_{(J-2)} \sqrt{\frac{\sum w_j (\hat{y}_{gj} - \hat{y}_g)^2}{N-1} + SE(\hat{y}_g)^2}$ (recommended for a small number of studies)


Where: $SE(\hat{y}_g) = \sqrt{\frac{s^2}{n_{gj}} + \frac{\tau_{gj}^2}{N}}$

Prediction intervals are based on the \(t\)-distribution, as explained in Higgins et al (2009): $\hat{y}_g \pm t_{(J-2)} \sqrt{\tau^2 + SE(\hat{y}_g)^2}$

Other supported methods for prediction intervals include:
 **Hartung-Knapp**, 
 **Kenward-Roger**,
 **Bootstrap Approach**, or 
 **Standard Normal Quantile**.
Detailed methodological overview can be found in the published [article](https://doi.org/10.48550/arXiv.2503.08389).
---
  
## The `MAC2` Function

```{r}
MAC2 <- function(data = NULL, preds, y, cluster, grid_length = 100, methods = c("log", "loess", "splines", "kde"),
                 span = 4, knots = 3, transf = "logit", method_choice = "splines",
                 method.tau = "REML", prediction = TRUE, random = TRUE, sm = "PLOGIT",
                 plot = TRUE, center_curves = FALSE, hakn = FALSE, linewidth = 1, method.predict = "HTS") {
  #' MAC2 Combined Function
  #'
  #' This function computes meta-analytical calibration (MAC) curves based on user-selected methods
  #' (logistic regression, loess, splines, or kernel density estimation) and performs meta-analysis
  #' across clusters to generate aggregated calibration curves. It also includes optional plotting
  #' of the meta-curve with confidence intervals and prediction intervals.
  #'
  #' @param data A data frame containing the input data. If NULL, separate arguments for `preds`, `y`,
  #'   and `cluster` must be provided.
  #' @param preds A numeric vector of predicted probabilities.
  #' @param y A numeric vector of binary outcomes (0 or 1).
  #' @param cluster A factor or character vector identifying cluster memberships.
  #' @param grid_length An integer specifying the length of the grid for calibration curve evaluation. Default is 100.
  #' @param methods A character vector specifying the methods to use for calibration. Options are
  #'   "log" (logistic regression), "loess", "splines", and "kde" (kernel density estimation).
  #' @param span Numeric, specifying the span for the loess smoother. Default is 4.
  #' @param knots Integer, specifying the number of knots for splines. Default is 3.
  #' @param transf A string specifying the transformation for predictions. Options are "logit" or "identity". Default is "logit".
  #' @param method_choice A string specifying which method to use for the meta-analysis.
  #'   Options are "log", "loess", "splines", or "kde". Default is "log".
  #' @param studlab A character vector of study labels for meta-analysis. Default is NULL.
  #' @param method.tau A string specifying the method for between-study heterogeneity estimation. Default is "REML".
  #' @param prediction Logical, indicating whether prediction intervals should be computed. Default is TRUE.
  #' @param random Logical, indicating whether a random-effects model should be used. Default is TRUE.
  #' @param sm A string specifying the summary measure for meta-analysis. Default is "PLOGIT".
  #' @param plot Logical, indicating whether to plot the calibration curves. Default is TRUE.
  #' @param center_curves Logical, indicating whether to center curves at the mean. Default is FALSE.
  #' @param hakn Logical, indicating whether to use the Hartung-Knapp adjustment. Default is FALSE.
  #' @param linewidth Numeric, specifying the line width for the meta-curve in the plot. Default is 1.
  #' @param method.predict A string specifying the method for prediction intervals. Default is "HTS".
  #'
  #' @return A list containing:
  #'   \describe{
  #'     \item{data_all_lp}{A data frame with linear predictors and their standard errors for each method.}
  #'     \item{meta_curve}{A data frame with meta-analysis results, including predictions and intervals.}
  #'     \item{plot}{A ggplot object showing the meta-curve and intervals (if `plot = TRUE`).}
  #'   }
  #'
  #' @details
  #' - This function calculates calibration curves for multiple methods (logistic regression, loess,
  #'   splines, and KDE) and aggregates them using meta-analysis.
  #' - The `method_choice` argument determines which method is used for the meta-analytical aggregation.
  #' - Plots include the meta-curve, 95% confidence intervals, and 95% prediction intervals.
  #'
  #' @examples
  #' # Example usage with simulated data:
  #' set.seed(123)
  #' data <- data.frame(
  #'   preds = runif(100),
  #'   y = rbinom(100, 1, 0.5),
  #'   cluster = sample(1:5, 100, replace = TRUE)
  #' )
  #' result <- MAC2_combined(data = data, preds = preds, y = y, cluster = cluster,
  #'                         methods = c("log", "loess", "splines", "kde"), method_choice = "splines")
  #'
  #' # Access the meta-curve:
  #' result$meta_curve
  #'
  #' # View the plot:
  #' print(result$plot)
  #'
  #' @export
  # Step 1: Grid computation (from MAC2_grid)
  if (!is.null(data)) {
    preds <- data[[deparse(substitute(preds))]]
    y <- data[[deparse(substitute(y))]]
    cluster <- data[[deparse(substitute(cluster))]]
  }

  data <- data.frame(predictions = preds, center = cluster, outcome = y)
  grid <- seq(0.01, 0.99, length.out = grid_length)
  data_all_lp <- data.frame()

  transform_function <- if (transf == "logit") qlogis else identity
  for (subcenter in unique(cluster)) {
    risk_cluster <- data %>% filter(center == subcenter)
    observed_grid <- data.frame(x = grid, center = subcenter, nsample = nrow(risk_cluster))
    risk_cluster$transf_preds <- transform_function(risk_cluster$predictions)

    if ("log" %in% methods) {
      log_model <- lrm(data = risk_cluster, outcome ~ transf_preds)
      log_data <- predict(log_model, newdata = data.frame(transf_preds = transform_function(grid)), type = "lp", se.fit = TRUE)
      log_data <- data.frame(log = log_data$linear.predictors, log_se = log_data$se.fit)
      observed_grid <- cbind(observed_grid, log_data)
    }

    if ("loess" %in% methods) {
      tryCatch(
        {
          loess_model <- fANCOVA::loess.as(
            x = risk_cluster$transf_preds, y = risk_cluster$outcome,
            degree = 2, criterion = "aicc", plot = FALSE,
            control = loess.control(surface = "direct")
          )
          loess_data <- predict(loess_model, newdata = data.frame(x = transform_function(grid)), se = TRUE)
          if (any(is.na(loess_data$fit)) || any(is.na(loess_data$se.fit))) {
            loess_data$fit <- zoo::na.approx(loess_data$fit, rule = 2)
            loess_data$se.fit <- zoo::na.approx(loess_data$se.fit, rule = 2)
          }
          loess_data$fit = pmin(pmax(loess_data$fit, 0.01), 0.99)

          loess_data <- data.frame(
            loess = transform_function(loess_data$fit),
            loess_se = abs(loess_data$se.fit / (loess_data$fit * (1 - loess_data$fit)))
          )
          observed_grid <- cbind(observed_grid, loess_data)
        },
        error = function(e) {
          message("LOESS was not computed because:", e)
        }
      )
    }

    if ("splines" %in% methods) {
      knots_sub <- knots
      splines_model <- suppressWarnings(lrm(data = risk_cluster, outcome ~ rcs(transf_preds, knots_sub)))
      while (splines_model$fail & knots_sub != 3) {
        knots_sub <- knots_sub - 1
        splines_model <- suppressWarnings(lrm(data = risk_cluster, outcome ~ rcs(transf_preds, knots_sub)))
      }
      if (knots_sub > 3) {
        splines_model3 <- suppressWarnings(lrm(data = risk_cluster, outcome ~ rcs(transf_preds, 3)))
        test <- lrtest(splines_model3, splines_model)
        if (test$stats["P"] > 0.05) {
          # Not Reject null so simple model is better than complex and we need to try with 4 knots.
          if (knots_sub > 4) {
            splines_model4 <- suppressWarnings(lrm(data = risk_cluster, outcome ~ rcs(transf_preds, 4)))
            if (!splines_model4$fail) {
              test <- lrtest(splines_model4, splines_model3)
            } else {
              test$stats["P"] <- 0
            }

            if (test$stats["P"] > 0.05) {
              splines_model <- splines_model4
            } else {
              splines_model <- splines_model3
            }
          } else {
            splines_model <- splines_model3
          }
        }
      } else {
        splines_model <- suppressWarnings(lrm(data = risk_cluster, outcome ~ transf_preds))
      }

      splines_data <- predict(splines_model, newdata = data.frame(transf_preds = transform_function(grid), knots_sub = knots_sub), type = "lp", se.fit = TRUE)
      splines_data <- data.frame(splines = splines_data$linear.predictors, splines_se = splines_data$se.fit)
      observed_grid <- cbind(observed_grid, splines_data)
    }

    if ("kde" %in% methods) {
      tryCatch(
        {
          kde_data <- kde_curve(risk_cluster$outcome, risk_cluster$predictions)
          observed_grid <- cbind(observed_grid, kde = kde_data$y)
        },
        error = function(e) {
          message("KDE was not computed because:", e)
        }
      )
    }

    data_all_lp <- rbind(data_all_lp, observed_grid)
  }

  # Step 2: Meta-analysis and plotting (from MAC2_curve)

  ### Create a switch with method


  adhoc.hakn.ci <- if (hakn) "IQWiG6" else NULL
  adhoc.hakn.pi <- if (hakn) "se" else NULL

  curve <- data.frame()

  for (value in unique(data_all_lp$x)) {
    data_v <- data_all_lp %>% filter(x == value)
    meta_inputs <- switch(method_choice,
      "log" = list(TE = data_v$log, seTE = data_v$log_se),
      "loess" = list(TE = data_v$loess, seTE = data_v$loess_se),
      "splines" = list(TE = data_v$splines, seTE = data_v$splines_se),
      "kde" = list(TE = data_v$kde, seTE = NA),
      stop("Invalid method choice")
    )

    meta <- meta::metagen(
      TE = meta_inputs$TE,
      seTE = meta_inputs$seTE,
      studlab = data_v$center,
      random = random,
      prediction = prediction,
      method.tau = method.tau,
      sm = sm,
      backtransf = TRUE,
      method.random.ci = hakn,
      method.predict = method.predict
    )

    data_v_b <- data.frame(
      y = plogis(meta$TE.random),
      upper = plogis(meta$upper.random),
      lower = plogis(meta$lower.random),
      up_pre = plogis(meta$upper.predict),
      low_pre = plogis(meta$lower.predict),
      tau = meta$tau2,
      x = value
    )
    curve <- rbind(curve, data_v_b)
  }

  p <- ggplot(data = curve) +
    geom_abline(linetype = "dashed", alpha = 0.1) +
    geom_ribbon(aes(x = x, ymin = pmax(0, pmin(lower, 1)), ymax = pmax(0, pmin(upper, 1)), fill = "CI 95%", alpha = "CI 95%")) +
    geom_ribbon(aes(x = x, ymin = pmax(0, pmin(low_pre, 1)), ymax = pmax(0, pmin(up_pre, 1)), fill = "PI 95%", alpha = "PI 95%")) +
    geom_line(aes(x = x, y = y), color = "black", linewidth = linewidth, linetype = "dashed") +
    xlab("Estimated probability") +
    ylab("Observed proportion") +
    theme_classic(base_size = 8) +
    scale_x_continuous(breaks = seq(0, 1, 0.1)) +
    scale_y_continuous(breaks = seq(0, 1, 0.2)) +
    scale_alpha_manual(values = c(0.4, 0.2), name = "Heterogeneity") +
    scale_fill_manual(values = c("red", "red"), name = "Heterogeneity") +
    coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +
    theme(legend.key.size = unit(0.3, "cm"), panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  if (center_curves) {
    p <- p + geom_line(data = data_all_lp, aes(x = x, y = plogis(data_all_lp[, method_choice]), group = center), lwd = linewidth / 2, show.legend = F, lty = "solid")
  }
  if (plot) print(p)

  return(list(data_all_lp = data_all_lp, meta_curve = curve, plot = p))
}
```

---
  
## Example: Simulated Clustered Data 

We use the superpopulation 1 from the simulation dataset presented in the published paper. Here we used one of the centers to train a model and then used the remaining centers to test the model performance (J = 15, N = 5000).
```{r}
data_test <- readRDS("data_test.rds")
```

---

## 2MAC (Splines)

```{r}
result_splines <- MAC2(
  data = data_test,
  preds = preds,
  y = y,
  cluster = center,
  method_choice = "splines",
  methods = "splines",
  plot = F,
  center_curves = F,
  transf = "logit",
  grid_length = 100
)

result_splines$plot
```
### Center specific curves
```{r}
result_splines$plot + 
  geom_line(data = result_splines$data_all_lp, aes(x = x, y = plogis(result_splines$data_all_lp$splines), group = center), lwd = 0.5, show.legend = F, lty = "solid") +
  labs(title = "Center specific splines curves")
```


---
  
## 2MAC (LOESS)

```{r}
result_loess <- MAC2(
  data = data_test,
  preds = preds,
  y = y,
  cluster = center,
  method_choice = "loess",
  methods = "loess",
  plot = F,
  center_curves = T,
  transf = "logit",
  grid_length = 100
)

result_loess$plot
```

---

## Interpretation

- **Black (dashed)**: 2MA-C pooled curve across clusters
- **Black (solid)**: Center specific curves (if `center_curves = TRUE`)
- **Red shaded areas**:
  - Light red = 95% Prediction Interval (expected calibration curve in new clusters)
  - Dark red = 95% Confidence Interval (expected calibration of the pooled curve)



2MA-C provides calibration estimates that account for cluster-level variability, making it more representative of model performance in new or unseen clusters and at the same time calculate center specific calibration curves. Note that in this example the clustering is based on normally distributed random effect, which might not be the case in real life scenarios. Due to this, the splines model seems to fit better than the loess model. However if the random effects follows a more complex structure, the loess model might be more appropriate.

---
  
## Methodological details
  
  
  
---
## References
  
1. Balduzzi S, R√ºcker G, Schwarzer G (2019), *How to perform a meta-analysis with R: a practical tutorial* , Evidence-Based Mental Health; 22: 153-160.
2. Barre√±ada, L., Campo, B. D. C., Wynants, L., & Calster, B. V. (2025). *Clustered Flexible Calibration Plots For Binary Outcomes Using Random Effects Modeling* (No. arXiv:2503.08389). arXiv. https://doi.org/10.48550/arXiv.2503.08389

